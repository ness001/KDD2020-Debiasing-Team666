{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "构建线下测试集underline_test\n",
    "选择每阶段underexpose_test_click.csv中user_id在当前阶段以及之前阶段所有click数据中的最后一次点击作为测试集\n",
    "'''\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "now_phase = 6\n",
    "train_path = os.path.join('../../data/underexpose_train')\n",
    "test_path = os.path.join('../../data/underexpose_test')\n",
    "click=pd.DataFrame()\n",
    "item_deg = defaultdict(lambda: 0) #item_deg是一个字典key=item_id, value=item_id的数量\n",
    "# answer_fname文件存储每个阶段线下测试集数据，格式phase_id, user_id, item_id, item_deg[item_id]\n",
    "answer_fname=r'../../user_data/debias_track_answer_%d.csv'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _create_answer_file_for_evaluation(phase_id,answer_fname):\n",
    "    train_test = user_path+'offline_train-%d.csv'\n",
    "\n",
    "    # underexpose_test_qtime-T.csv contains only <user_id, time>\n",
    "    # underexpose_test_qtime_with_answer-T.csv contains <user_id, item_id, time>\n",
    "    # answer = 'underexpose_test_qtime_with_answer-%d.csv'  # not released\n",
    "    answer=user_path+'offline_test-%d.csv'\n",
    "    item_deg = defaultdict(lambda: 0)\n",
    "    with open(answer_fname % phase_id, 'w') as fout:\n",
    "        with open(train_test % phase_id) as fin:\n",
    "            for line in fin:\n",
    "                user_id, item_id, timestamp = line.split(',')\n",
    "                user_id, item_id, timestamp = (\n",
    "                    int(user_id), int(item_id), float(timestamp))\n",
    "                item_deg[item_id] += 1\n",
    "        with open(answer % phase_id) as fin:\n",
    "            for line in fin:\n",
    "                user_id, item_id, timestamp = line.split(',')\n",
    "                user_id, item_id, timestamp = (\n",
    "                    int(user_id), int(item_id), float(timestamp))\n",
    "                assert user_id % 11 == phase_id\n",
    "                print(phase_id, user_id, item_id, item_deg[item_id],\n",
    "                      sep=',', file=fout)\n",
    "\n",
    "\n",
    "def evaluate_each_phase(predictions, answers):\n",
    "    list_item_degress = []\n",
    "    for user_id in answers:\n",
    "        item_id, item_degree = answers[user_id]\n",
    "        list_item_degress.append(item_degree)\n",
    "    list_item_degress.sort()\n",
    "    median_item_degree = list_item_degress[len(list_item_degress) // 2]\n",
    "\n",
    "    num_cases_full = 0.0\n",
    "    ndcg_50_full = 0.0\n",
    "    ndcg_50_half = 0.0\n",
    "    num_cases_half = 0.0\n",
    "    hitrate_50_full = 0.0\n",
    "    hitrate_50_half = 0.0\n",
    "    for user_id in answers:\n",
    "        item_id, item_degree = answers[user_id]\n",
    "        rank = 0\n",
    "        while rank < 50 and predictions[user_id][rank] != item_id:\n",
    "            rank += 1\n",
    "        num_cases_full += 1.0\n",
    "        if rank < 50:\n",
    "            ndcg_50_full += 1.0 / np.log2(rank + 2.0)\n",
    "            hitrate_50_full += 1.0\n",
    "        if item_degree <= median_item_degree:\n",
    "            num_cases_half += 1.0\n",
    "            if rank < 50:\n",
    "                ndcg_50_half += 1.0 / np.log2(rank + 2.0)\n",
    "                hitrate_50_half += 1.0\n",
    "    ndcg_50_full /= num_cases_full\n",
    "    hitrate_50_full /= num_cases_full\n",
    "    ndcg_50_half /= num_cases_half\n",
    "    hitrate_50_half /= num_cases_half\n",
    "\n",
    "    return np.array([ndcg_50_full, ndcg_50_half,\n",
    "                     hitrate_50_full, hitrate_50_half], dtype=np.float32)\n",
    "\n",
    "def get_rec():\n",
    "    pass\n",
    "answers = [{} for _ in range(now_phase+1)]\n",
    "for p in range(0, now_phase + 1):\n",
    "    print('phase:', p)\n",
    "\n",
    "    click_train = pd.read_csv(train_path + '/underexpose_train_click-{}.csv'.format(p), header=None, nrows=None,\n",
    "                              names=['user_id', 'item_id', 'time'],\n",
    "                              dtype={'user_id':np.int, 'item_id':np.int, 'time':np.float32})\n",
    "    click_test = pd.read_csv(test_path + '/underexpose_test_click-{}/underexpose_test_click-{}.csv'.format(p, p), header=None, nrows=None,\n",
    "                             names=['user_id', 'item_id', 'time'],\n",
    "                             dtype={'user_id': np.int, 'item_id': np.int, 'time': np.float32})\n",
    "    user_test=set(click_test['user_id'])  # 每阶段线下测试集用户集合\n",
    "    print('len(user_val):', len(user_test))\n",
    "\n",
    "\n",
    "\n",
    "    click_train_test = click_train.append(click_test)\n",
    "    click=click.append(click_train_test,sort=True)  # 当前阶段以及之前阶段click数据\n",
    "    click = click.sort_values('time')       # 时间排序\n",
    "    click= click.drop_duplicates(['user_id', 'item_id', 'time'], keep='last') # 其他phase数据加入去重\n",
    "    click['pred'] = click['user_id'].map(lambda x: 'test' if x in user_test else 'train') #这样的话相当于只将当前阶段的最后一次设置为test，其他都是train的数据，即这样子test中只有最后一个phase最后依次点击的数据\n",
    "\n",
    "    offline_test = click[click['pred'] == 'test'].drop_duplicates(['user_id'], keep='last')  # 只保留最后一次点击\n",
    "    offline_train = click.append(offline_test).drop_duplicates(keep=False)  # 当前阶段以及之前阶段训练集click数据\n",
    "    assert (offline_test['user_id'].count() + offline_train['user_id'].count() == click['user_id'].count())\n",
    "    user_path='../../user_data/offline/'\n",
    "    offline_train=offline_train.reindex(['user_id', 'item_id', 'time', 'pred'], axis=1)\n",
    "    offline_test=offline_test.reindex(['user_id', 'item_id', 'time', 'pred'], axis=1)\n",
    "    offline_train.drop(['pred'],axis=1).to_csv(user_path +'offline_train-{}.csv'.format(p), index=False, header=False)\n",
    "    offline_test.drop(['pred'],axis=1).to_csv(user_path +'offline_test-{}.csv'.format(p), index=False, header=False)\n",
    "    \n",
    "    #gen fake answer debias track answer file\n",
    "    answer_fname='../../prediction_result/debias_track_answer-%d.csv'\n",
    "    _create_answer_file_for_evaluation(p, answer_fname)\n",
    "\n",
    "    #gen fake answer dict for all p\n",
    "\n",
    "    with open(answer_fname % p, 'r') as fin:\n",
    "        for line in fin:\n",
    "            line = [int(x) for x in line.split(',')]\n",
    "            phase_id, user_id, item_id, item_degree = line\n",
    "            assert user_id % 11 == phase_id\n",
    "            # exactly one test case for each user_id\n",
    "            answers[phase_id][user_id] = (item_id, item_degree)\n",
    "    \n",
    "\n",
    "    # pred_df= get_rec(offline_train,offline_test.user_id.unique())\n",
    "pred_path='../../prediction_result/'\n",
    "pred_df=pd.read_csv(pred_path+'recall_allvec_df.csv',low_memory=False, quoting=csv.QUOTE_NONE, error_bad_lines=False)\n",
    "pred_df=pred_df.loc[pred_df['rank'] <=50 ]\n",
    "preds={}\n",
    "for user in pred_df.user_id.unique():\n",
    "    assert len(pred_df.loc[pred_df.user_id == user ]) == 50\n",
    "    # try:\n",
    "    #     index_list=pred_df.loc[pred_df.user_id == user ].index[:50]\n",
    "    #     preds[int(user)] = pred_df.iloc[index_list].item_id_pred.astype(int).to_list()\n",
    "    # except IOError:\n",
    "    #     print( len(pred_df.loc[pred_df.user_id == user ]) == 50, 'user id',user)\n",
    "    index_list = pred_df.loc[pred_df.user_id == user].index[:50] # it returns row labels\n",
    "    preds[int(user)] = pred_df.loc[index_list].item_id_pred.astype(int).to_list()\n",
    "\n",
    "    \n",
    "\n",
    "'''\n",
    "下面这段不行，item_id的个数会被重复计算，因为此时temp_是累积phase的数据\n",
    "比如 对于phase=1， item_deg[1]=4是phase0的结果\n",
    "但是此时click train test数据集中并没有itemid==1的数据\n",
    "但是agg出的数据依然是4，那么item_deg[1]就被累积更新为8\n",
    "这是错误的\n",
    "'''\n",
    "\n",
    "# # 获取当前阶段以及之前阶段item_deg字典，item_id对应的点击次数，用作ndcg_topk_half和hitrate_topk_half统计\n",
    "    # temp_=click\n",
    "    # temp_=temp_.groupby(['item_id'], as_index=False).agg({'user_id':'count'})\n",
    "    # temp_.columns=['item_id','count']\n",
    "    # for item_id,item_count in zip(list(temp_['item_id'].values), list(temp_['count'].values)):\n",
    "    #     item_deg[item_id]+=item_count\n",
    "\n",
    "\n",
    "'''\n",
    "同理下面这段也是错误的\n",
    "'''\n",
    "    # with open(answer_fname % c, 'w') as fout:\n",
    "    #     for i, row in underline_test.iterrows():\n",
    "    #         user_id, item_id, timestamp = (int(row[0]), int(row[1]), row[2])\n",
    "    #         assert user_id % 11 == c\n",
    "    #         print(c, user_id, item_id, item_deg[item_id], sep=',', file=fout)\n",
    "    #\n",
    "\n",
    "\n",
    "\n",
    "top50_items = list(click['item_id'].value_counts().index[:50])\n",
    "user_to_be_filled= answers[p].keys() - preds.keys()\n",
    "for user in user_to_be_filled:\n",
    "    preds[user] = top50_items\n",
    "\n",
    "evaluate_score = evaluate_each_phase(predictions=preds,answers=answers[p])\n",
    "print(\"------------- eval result -------------\")\n",
    "print(\"hitrate_50_full : \", evaluate_score[2],'\\n','  ndcg_50_full : ', evaluate_score[0], '\\n')\n",
    "print(\"hitrate_50_half : \", evaluate_score[3],'\\n','  ndcg_50_half : ', evaluate_score[1], '\\n')\n",
    "print(\"score:\",evaluate_score[0],'\\n')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
