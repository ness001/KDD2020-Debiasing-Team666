{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "now_phase = 6\n",
    "user_path=os.path.expanduser('~')   #用户目录\n",
    "train_path = os.path.join(user_path, r'kdd\\data\\underexpose_train')\n",
    "test_path = os.path.join(user_path, r'kdd\\data\\underexpose_test')\n",
    "click=pd.DataFrame()\n",
    "item_deg = defaultdict(lambda: 0) #item_deg是一个字典key=item_id, value=item_id的数量\n",
    "# answer_fname文件存储每个阶段线下测试集数据，格式phase_id, user_id, item_id, item_deg[item_id]\n",
    "answer_fname=r'data\\debias_track_answer_%d.csv'\n",
    "user_items_dict_file=r'data\\user_items_dict_%d.txt'\n",
    "item_feat_file=os.path.join(train_path,r'underexpose_item_feat.csv')\n",
    "item_set_for_feat=set()\n",
    "interacted_user_items_dict=dict()\n",
    "item_set=set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取用户-商品列表的字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_items_dict(underline_train, phase):\n",
    "    underline_train=click.append(underline_test).drop_duplicates(keep=False)  #当前阶段以及之前阶段训练集click数据\n",
    "    user_item_ = underline_train.groupby('user_id')['item_id'].agg(list).reset_index()\n",
    "    # user_items_dict是一个字典，key=user_id,value=用户点击的item列表\n",
    "    user_items_dict = dict(zip(user_item_['user_id'], user_item_['item_id']))\n",
    "    with open(user_items_dict_file % phase, 'w') as fin:\n",
    "        temp=str(user_items_dict)\n",
    "        fin.write(temp)\n",
    "    return user_items_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取每个阶段top500 click item列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hot_list_500(underline_train, phase):\n",
    "    top500_click = underline_train['item_id'].value_counts().index[:500].values  # 最热商品\n",
    "    hot_list = list(top500_click)\n",
    "    with open(r'data\\item_topk500_%d' %phase,'w') as f:\n",
    "        temp=str(hot_list)\n",
    "        f.write(temp)\n",
    "    return hot_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取线下测试集underline_test中用户购买的item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_underline_test_answer(underline_test):\n",
    "    with open(answer_fname % c, 'w') as fout:\n",
    "        for i, row in underline_test.iterrows():\n",
    "            user_id, item_id, timestamp = (int(row[0]), int(row[1]), row[2])\n",
    "            assert user_id % 11 == c\n",
    "            print(c, user_id, item_id, item_deg[item_id], sep=',', file=fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取item-counts字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_counts(underline_train):\n",
    "    temp=underline_train.groupby('item_id',as_index=False)['item_id'].agg({'item_id':'count'})\n",
    "    print(temp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据处理主要执行块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase: 0\n",
      "len(user_val): 1663\n",
      "underline_test: 1663\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot insert item_id, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-07ee5a18bec4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m#     hot_list=get_hot_list_500(underline_train,c)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;31m#     get_underline_test_answer(underline_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mget_item_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munderline_train_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m#     for user_id in user_test:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-2aab8d86b7de>\u001b[0m in \u001b[0;36mget_item_counts\u001b[1;34m(underline_train)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_item_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munderline_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtemp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0munderline_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'item_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mas_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'item_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'item_id'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'count'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36maggregate\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    960\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 962\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insert_inaxis_grouper_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    963\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36m_insert_inaxis_grouper_inplace\u001b[1;34m(self, result)\u001b[0m\n\u001b[0;32m   1668\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_axis\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mizip\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1669\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0min_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1670\u001b[1;33m                 \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1671\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1672\u001b[0m     def _wrap_aggregated_output(\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36minsert\u001b[1;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[0;32m   3494\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3495\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3496\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_duplicates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_duplicates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3498\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"DataFrame\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36minsert\u001b[1;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[0;32m   1171\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m             \u001b[1;31m# Should this be a different kind of error??\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1173\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"cannot insert {item}, already exists\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot insert item_id, already exists"
     ]
    }
   ],
   "source": [
    "for c in range(0,now_phase + 1):\n",
    "    print('phase:', c)\n",
    "    click_train = pd.read_csv(train_path + '\\\\underexpose_train_click-{}.csv'.format(c), header=None,nrows=None,\n",
    "                              names=['user_id', 'item_id', 'time'],\n",
    "                              dtype={'user_id':np.int, 'item_id':np.int, 'time':np.float32})\n",
    "    click_test = pd.read_csv(test_path + '\\\\underexpose_test_click-{}.csv'.format(c), header=None,nrows=None,\n",
    "                             names=['user_id', 'item_id', 'time'],\n",
    "                             dtype={'user_id': np.int, 'item_id': np.int, 'time': np.float32})\n",
    "\n",
    "    user_test=set(click_test['user_id'])  # 每阶段线下测试集用户集合\n",
    "    print('len(user_val):', len(user_test))\n",
    "\n",
    "    click_train_test = click_train.append(click_test)\n",
    "    click=click.append(click_train_test)  # 当前阶段以及之前阶段click数据\n",
    "    click = click.sort_values('time')       # 时间排序\n",
    "    click= click.drop_duplicates(['user_id', 'item_id', 'time'], keep='last') # 去重\n",
    "    item_set.update(set(click['item_id'].values))\n",
    "    \n",
    "    # 获取当前阶段以及之前阶段item_deg字典，item_id对应的点击次数，用作ndcg_topk_half和hitrate_topk_half统计\n",
    "    temp_=click\n",
    "    temp_=temp_.groupby(['item_id'], as_index=False).agg({'user_id':'count'})\n",
    "    temp_.columns=['item_id','count']\n",
    "    for item_id,item_count in zip(list(temp_['item_id'].values), list(temp_['count'].values)):\n",
    "        item_deg[item_id]+=item_count\n",
    "\n",
    "    click['pred'] = click['user_id'].map(lambda x: 'test' if x in user_test else 'train')\n",
    "    underline_test=click[click['pred']=='test'].drop_duplicates(['user_id'], keep='last') #当前阶段线下测试集click数据\n",
    "    underline_train_val = click.append(underline_test).drop_duplicates(keep=False)            #当前阶段以及之前阶段训练集click数据\n",
    "    assert (underline_test['user_id'].count()+underline_train_val['user_id'].count()==click['user_id'].count())\n",
    "    print('underline_test:', underline_test['user_id'].count())\n",
    "#     user_items_dict=get_user_items_dict(underline_train, c)\n",
    "#     hot_list=get_hot_list_500(underline_train,c)\n",
    "#     get_underline_test_answer(underline_test)\n",
    "    get_item_counts(underline_train_val)\n",
    "\n",
    "#     for user_id in user_test:\n",
    "#         interacted_items=user_items_dict[user_id]\n",
    "#         interacted_user_items_dict[user_id]=interacted_items\n",
    "# with open('data\\\\interacted_user_items_dict_file.txt','w') as fout:\n",
    "#     temp_str=str(interacted_user_items_dict)\n",
    "#     fout.write(temp_str)\n",
    "print(len(item_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(item_feat_file,'r') as fin:\n",
    "    for line in fin:\n",
    "        line=line.strip().split(',[')\n",
    "        item_id=int(line[0])\n",
    "        item_set_for_feat.add(item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner=item_set & item_set_for_feat\n",
    "print(len(inner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "78380 in item_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "78380 in item_set_for_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
